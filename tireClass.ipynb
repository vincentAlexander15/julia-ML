{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- prepare data\n",
    "- process data\n",
    "- build the CNN\n",
    "- compile the model\n",
    "- train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mLoadError: InitError: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "could not load library \"C:\\Users\\Vincent Alexander\\.julia\\artifacts\\0cdffaf70d865a7149744c4c5670ea6b2145e80d\\bin\\cublas64_12.dll\"\n",
      "The specified module could not be found. \n",
      "Stacktrace:\n",
      "  [1] \u001b[0m\u001b[1mdlopen\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ms\u001b[39m::\u001b[0mString, \u001b[90mflags\u001b[39m::\u001b[0mUInt32; \u001b[90mthrow_error\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase.Libc.Libdl\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlibdl.jl:117\u001b[24m\u001b[39m\n",
      "  [2] \u001b[0m\u001b[1mdlopen\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ms\u001b[39m::\u001b[0mString, \u001b[90mflags\u001b[39m::\u001b[0mUInt32\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase.Libc.Libdl\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlibdl.jl:116\u001b[24m\u001b[39m\n",
      "  [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mC:\\Users\\Vincent Alexander\\.julia\\packages\\JLLWrappers\\pG9bm\\src\\products\\\u001b[39m\u001b[90m\u001b[4mlibrary_generators.jl:63\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [4] \u001b[0m\u001b[1m__init__\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[35mCUDA_Runtime_jll\u001b[39m \u001b[90mC:\\Users\\Vincent Alexander\\.julia\\packages\\CUDA_Runtime_jll\\wIIfE\\src\\wrappers\\\u001b[39m\u001b[90m\u001b[4mx86_64-w64-mingw32-cuda+12.2.jl:29\u001b[24m\u001b[39m\n",
      "  [5] \u001b[0m\u001b[1mregister_restored_modules\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90msv\u001b[39m::\u001b[0mCore.SimpleVector, \u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1115\u001b[24m\u001b[39m\n",
      "  [6] \u001b[0m\u001b[1m_include_from_serialized\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString, \u001b[90mocachepath\u001b[39m::\u001b[0mString, \u001b[90mdepmods\u001b[39m::\u001b[0mVector\u001b[90m{Any}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1061\u001b[24m\u001b[39m\n",
      "  [7] \u001b[0m\u001b[1m_require_search_from_serialized\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90msourcepath\u001b[39m::\u001b[0mString, \u001b[90mbuild_id\u001b[39m::\u001b[0mUInt128\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1506\u001b[24m\u001b[39m\n",
      "  [8] \u001b[0m\u001b[1m_require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1783\u001b[24m\u001b[39m\n",
      "  [9] \u001b[0m\u001b[1m_require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1660\u001b[24m\u001b[39m\n",
      " [10] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1648\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [11] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:267\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [12] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1611\u001b[24m\u001b[39m\n",
      " [13] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:457\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [14] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt128}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2049\u001b[24m\u001b[39m\n",
      " [15] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90m\u001b[4mstdin:3\u001b[24m\u001b[39m\n",
      "during initialization of module CUDA_Runtime_jll\n",
      "in expression starting at C:\\Users\\Vincent Alexander\\.julia\\packages\\CUDA\\nbRJk\\src\\CUDA.jl:1\n",
      "in expression starting at stdin:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mLoadError: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to precompile CUDA [052768ef-5323-5732-b1bb-66c8b64840ba] to \"C:\\\\Users\\\\Vincent Alexander\\\\.julia\\\\compiled\\\\v1.9\\\\CUDA\\\\jl_5F6B.tmp\".\n",
      "Stacktrace:\n",
      "  [1] \u001b[0m\u001b[1merror\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ms\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4merror.jl:35\u001b[24m\u001b[39m\n",
      "  [2] \u001b[0m\u001b[1mcompilecache\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString, \u001b[90minternal_stderr\u001b[39m::\u001b[0mIO, \u001b[90minternal_stdout\u001b[39m::\u001b[0mIO, \u001b[90mkeep_loaded_modules\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2300\u001b[24m\u001b[39m\n",
      "  [3] \u001b[0m\u001b[1mcompilecache\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2167\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [4] \u001b[0m\u001b[1m_require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1805\u001b[24m\u001b[39m\n",
      "  [5] \u001b[0m\u001b[1m_require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90menv\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1660\u001b[24m\u001b[39m\n",
      "  [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1648\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [7] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:267\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [8] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1611\u001b[24m\u001b[39m\n",
      "  [9] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:457\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [10] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt128}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:2049\u001b[24m\u001b[39m\n",
      " [11] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90m\u001b[4mstdin:3\u001b[24m\u001b[39m\n",
      "in expression starting at C:\\Users\\Vincent Alexander\\.julia\\packages\\LuxCUDA\\3LXGg\\src\\LuxCUDA.jl:1\n",
      "in expression starting at stdin:3\n"
     ]
    },
    {
     "ename": "ErrorException",
     "evalue": "Failed to precompile LuxCUDA [d0bbae9a-e099-4d5b-a835-1c6931763bda] to \"C:\\\\Users\\\\Vincent Alexander\\\\.julia\\\\compiled\\\\v1.9\\\\LuxCUDA\\\\jl_5D89.tmp\".",
     "output_type": "error",
     "traceback": [
      "Failed to precompile LuxCUDA [d0bbae9a-e099-4d5b-a835-1c6931763bda] to \"C:\\\\Users\\\\Vincent Alexander\\\\.julia\\\\compiled\\\\v1.9\\\\LuxCUDA\\\\jl_5D89.tmp\".\n",
      "\n",
      "Stacktrace:\n",
      "  [1] error(s::String)\n",
      "    @ Base .\\error.jl:35\n",
      "  [2] compilecache(pkg::Base.PkgId, path::String, internal_stderr::IO, internal_stdout::IO, keep_loaded_modules::Bool)\n",
      "    @ Base .\\loading.jl:2300\n",
      "  [3] compilecache\n",
      "    @ .\\loading.jl:2167 [inlined]\n",
      "  [4] _require(pkg::Base.PkgId, env::String)\n",
      "    @ Base .\\loading.jl:1805\n",
      "  [5] _require_prelocked(uuidkey::Base.PkgId, env::String)\n",
      "    @ Base .\\loading.jl:1660\n",
      "  [6] macro expansion\n",
      "    @ .\\loading.jl:1648 [inlined]\n",
      "  [7] macro expansion\n",
      "    @ .\\lock.jl:267 [inlined]\n",
      "  [8] require(into::Module, mod::Symbol)\n",
      "    @ Base .\\loading.jl:1611\n",
      "  [9] eval\n",
      "    @ .\\boot.jl:370 [inlined]\n",
      " [10] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)\n",
      "    @ Base .\\loading.jl:1903\n",
      " [11] #invokelatest#2\n",
      "    @ .\\essentials.jl:819 [inlined]\n",
      " [12] invokelatest\n",
      "    @ .\\essentials.jl:816 [inlined]\n",
      " [13] (::VSCodeServer.var\"#202#203\"{VSCodeServer.NotebookRunCellArguments, String})()\n",
      "    @ VSCodeServer c:\\Users\\Vincent Alexander\\.vscode\\extensions\\julialang.language-julia-1.60.2\\scripts\\packages\\VSCodeServer\\src\\serve_notebook.jl:19\n",
      " [14] withpath(f::VSCodeServer.var\"#202#203\"{VSCodeServer.NotebookRunCellArguments, String}, path::String)\n",
      "    @ VSCodeServer c:\\Users\\Vincent Alexander\\.vscode\\extensions\\julialang.language-julia-1.60.2\\scripts\\packages\\VSCodeServer\\src\\repl.jl:274\n",
      " [15] notebook_runcell_request(conn::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, params::VSCodeServer.NotebookRunCellArguments)\n",
      "    @ VSCodeServer c:\\Users\\Vincent Alexander\\.vscode\\extensions\\julialang.language-julia-1.60.2\\scripts\\packages\\VSCodeServer\\src\\serve_notebook.jl:13\n",
      " [16] dispatch_msg(x::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, dispatcher::VSCodeServer.JSONRPC.MsgDispatcher, msg::Dict{String, Any})\n",
      "    @ VSCodeServer.JSONRPC c:\\Users\\Vincent Alexander\\.vscode\\extensions\\julialang.language-julia-1.60.2\\scripts\\packages\\JSONRPC\\src\\typed.jl:67\n",
      " [17] serve_notebook(pipename::String, outputchannel_logger::Base.CoreLogging.SimpleLogger; crashreporting_pipename::String)\n",
      "    @ VSCodeServer c:\\Users\\Vincent Alexander\\.vscode\\extensions\\julialang.language-julia-1.60.2\\scripts\\packages\\VSCodeServer\\src\\serve_notebook.jl:139\n",
      " [18] top-level scope\n",
      "    @ c:\\Users\\Vincent Alexander\\.vscode\\extensions\\julialang.language-julia-1.60.2\\scripts\\notebook\\notebook.jl:32"
     ]
    }
   ],
   "source": [
    "#import everything important (might have to download first)\n",
    "import Pkg;\n",
    "# Pkg.add(\"LuxAMDGPU\")\n",
    "# Pkg.add(\"LuxCUDA\")\n",
    "# Pkg.add(\"JLD2\")\n",
    "# Pkg.add(\"MLUtils\")\n",
    "# Pkg.add(\"Optimisers\")\n",
    "# Pkg.add(\"Zygote\")\n",
    "# Pkg.add(\"Random\")\n",
    "# Pkg.add(\"Statistics\")\n",
    "# Pkg.add(\"Images\")\n",
    "# Pkg.add(\"FileIO\")\n",
    "# Pkg.add(\"IterTools\")\n",
    "# Pkg.add(\"OneHotArrays\")\n",
    "using Lux, LuxAMDGPU, LuxCUDA, JLD2, MLUtils, Optimisers, Zygote, Random, Statistics, Images, FileIO, IterTools, OneHotArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image processing (assumes data is split into 'good' and 'defective' folders)\n",
    "using Images\n",
    "using Statistics\n",
    "\n",
    "global good_path = \"C:\\\\Users\\\\Vincent Alexander\\\\OneDrive\\\\Desktop\\\\good\" #set as global to be accessed in train function\n",
    "global defective_path = \"C:\\\\Users\\\\Vincent Alexander\\\\OneDrive\\\\Desktop\\\\defective\"\n",
    "\n",
    "function imgProcess(dir_path::AbstractString, output_path::AbstractString, width::Int, height::Int)\n",
    "    for filename in readdir(dir_path)\n",
    "        if endswith(filename, \".jpg\")\n",
    "            img_path = joinpath(dir_path, filename)\n",
    "            img = load(img_path)\n",
    "            #resize image\n",
    "            resizedImage = imresize(img, width, height)\n",
    "            #convert to array to normalize\n",
    "            arr = Array(resizedImage)\n",
    "            mean_val = mean(arr)\n",
    "            std_val = std(arr)\n",
    "            normalized_image = (arr .- mean_val) / std_val\n",
    "            #grayscale the image\n",
    "            processed_image = Gray.(normalized_image)\n",
    "            #save processed image in new path\n",
    "            save(joinpath(output_path, filename), processed_image)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "imgProcess(good_path, \"processed_good_path\", 224, 224)\n",
    "imgProcess(defective_path, \"processed_defective_path\", 224, 224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_data (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Collects tire data and splits into batches for training/testing\n",
    "using Random\n",
    "using OneHotArrays\n",
    "using Images\n",
    "using MLUtils\n",
    "using Statistics\n",
    "\n",
    "function load_data(good_tire_path::String, defective_tire_path::String, batchsize::Int64, train_split::Float64)\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    #put good tires and corresponding labels into x/y data\n",
    "    for (i, file) in enumerate(readdir(good_tire_path))\n",
    "        img = load(joinpath(good_tire_path, file))\n",
    "        push!(x_data, img)\n",
    "        push!(y_data, 0) #Assign 0 label for good tires\n",
    "    end\n",
    "    #put defective tires and corresponding labels into x/y data\n",
    "    for (i, file) in enumerate(readdir(defective_tire_path))\n",
    "        img = load(joinpath(defective_tire_path, file))\n",
    "        push!(x_data, img)\n",
    "        push!(y_data, 1) #Assign 1 label for defective tires\n",
    "    end\n",
    "    #stack images along fourth dimension\n",
    "    x_data = cat(x_data...; dims=4)\n",
    "    #shuffle data\n",
    "    N = length(x_data[1, 1, 1, :])\n",
    "    num_train = Int(floor(N * train_split))\n",
    "    indicies = shuffle(1:N)\n",
    "    \n",
    "    #split data into training and testing sets\n",
    "    x_train = x_data[:, :, :, indicies[1:num_train]]\n",
    "    x_test = x_data[:, :, :, indicies[(num_train + 1):end]]\n",
    "\n",
    "    y_data = onehotbatch(y_data, 0:1)\n",
    "    y_train = y_data[:, indicies[1:num_train]]\n",
    "    y_test = y_data[:, indicies[(num_train+1):end]]\n",
    "    \n",
    "    train_loader = MLUtils.DataLoader((x_train, y_train), batchsize)\n",
    "    test_loader = MLUtils.DataLoader((x_test, y_test), batchsize)\n",
    "    return train_loader, test_loader\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "    layer_1 = Conv((3, 3), 3 => 16, relu),  \u001b[90m# 448 parameters\u001b[39m\n",
       "    layer_2 = MaxPool((2, 2)),\n",
       "    layer_3 = Conv((3, 3), 16 => 32, relu),  \u001b[90m# 4_640 parameters\u001b[39m\n",
       "    layer_4 = MaxPool((2, 2)),\n",
       "    layer_5 = GlobalMeanPool(),\n",
       "    layer_6 = Dense(32 => 128, relu),   \u001b[90m# 4_224 parameters\u001b[39m\n",
       "    layer_7 = Dense(128 => 2, sigmoid_fast),  \u001b[90m# 258 parameters\u001b[39m\n",
       ") \u001b[90m        # Total: \u001b[39m9_570 parameters,\n",
       "\u001b[90m          #        plus \u001b[39m0 states."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#establish the model\n",
    "\n",
    "#define model using chain of layers\n",
    "model = Chain(\n",
    "   Conv((3, 3), 3 => 16, relu),\n",
    "   MaxPool((2, 2)),\n",
    "   Conv((3, 3), 16 => 32, relu),\n",
    "   MaxPool((2, 2)),\n",
    "   GlobalMeanPool(),\n",
    "   Dense(32, 128, relu),  # Adjust the input size (32) and output size (128)\n",
    "   Dense(128, 2, sigmoid),  # 2 classes (good or bad)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define the loss function\n",
    "function xlogy(x, y)\n",
    "    result = x * log(y)\n",
    "    return ifelse(iszero(x), zero(result), result)\n",
    "end\n",
    "\n",
    "function binarycrossentropy(y_pred, y_true)\n",
    "    y_pred = y_pred .+ eps(eltype(y_pred))\n",
    "    return mean(@. -xlogy(y_true, y_pred) - xlogy(1 - y_true, 1 - y_pred))\n",
    "end\n",
    "\n",
    "function compute_loss(x, y, model, ps, st)\n",
    "    y_pred, st = model(x, ps, st)\n",
    "    return binarycrossentropy(y_pred, y), y_pred, st\n",
    "end\n",
    "\n",
    "matches(y_pred, y_true) = sum((y_pred .> 0.5) .== y_true)\n",
    "accuracy(y_pred, y_true) = matches(y_pred, y_true) / length(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_optimiser (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define optimiser\n",
    "function create_optimiser(ps)\n",
    "    opt = Optimisers.ADAM(0.01f0)\n",
    "    return Optimisers.setup(opt, ps)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching DataLoader(::Tuple{Array{Gray{N0f8}, 4}, OneHotMatrix{UInt32, Vector{UInt32}}}, ::Int64)\n\nClosest candidates are:\n  DataLoader(::T, ::Int64, !Matched::Bool, !Matched::Bool, !Matched::Bool, !Matched::Bool, !Matched::C, !Matched::R) where {T, R<:AbstractRNG, C<:Val}\n   @ MLUtils C:\\Users\\Vincent Alexander\\.julia\\packages\\MLUtils\\n3C0h\\src\\eachobs.jl:128\n  DataLoader(::Any; buffer, parallel, shuffle, batchsize, partial, collate, rng)\n   @ MLUtils C:\\Users\\Vincent Alexander\\.julia\\packages\\MLUtils\\n3C0h\\src\\eachobs.jl:138\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching DataLoader(::Tuple{Array{Gray{N0f8}, 4}, OneHotMatrix{UInt32, Vector{UInt32}}}, ::Int64)\n",
      "\n",
      "Closest candidates are:\n",
      "  DataLoader(::T, ::Int64, !Matched::Bool, !Matched::Bool, !Matched::Bool, !Matched::Bool, !Matched::C, !Matched::R) where {T, R<:AbstractRNG, C<:Val}\n",
      "   @ MLUtils C:\\Users\\Vincent Alexander\\.julia\\packages\\MLUtils\\n3C0h\\src\\eachobs.jl:128\n",
      "  DataLoader(::Any; buffer, parallel, shuffle, batchsize, partial, collate, rng)\n",
      "   @ MLUtils C:\\Users\\Vincent Alexander\\.julia\\packages\\MLUtils\\n3C0h\\src\\eachobs.jl:138\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] load_data(good_tire_path::String, defective_tire_path::String, batchsize::Int64, train_split::Float64)\n",
      "   @ Main c:\\Users\\Vincent Alexander\\OneDrive\\Desktop\\Julia\\tireClass.ipynb:38\n",
      " [2] top-level scope\n",
      "   @ c:\\Users\\Vincent Alexander\\OneDrive\\Desktop\\Julia\\tireClass.ipynb:4"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "batchsize = 100\n",
    "train_split = 0.6\n",
    "train_loader, test_loader = load_data(\"processed_good_path\", \"processed_defective_path\", batchsize, train_split)\n",
    "\n",
    "ps = params(model)\n",
    "\n",
    "optimiser = create_optimiser(ps)\n",
    "init!(optimiser, ps)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "function train(train_loader, test_loader, model, optimiser, ps, epochs)\n",
    "    for epoch in 1:epochs\n",
    "        total_loss = 0.0\n",
    "    \n",
    "        for (x, y) in train_loader\n",
    "            grads, loss = gradient(ps) do\n",
    "                y_pred = model(x, ps)\n",
    "                loss, y_pred = compute_loss(x, y, model, ps, nothing )\n",
    "            end\n",
    "            total_loss += loss\n",
    "            update!(optimizer, ps, grads)\n",
    "        end\n",
    "    \n",
    "        println(\"Epoch: $epoch, Loss: $total_loss\")\n",
    "    end\n",
    "end\n",
    "\n",
    "train(train_loader, test_loader, model, optimiser, ps, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
