{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- prepare data\n",
    "- process data\n",
    "- build the CNN\n",
    "- compile the model\n",
    "- train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import everything important (might have to download first)\n",
    "import Pkg;\n",
    "# Pkg.add(\"LuxAMDGPU\")\n",
    "# Pkg.add(\"LuxCUDA\")\n",
    "# Pkg.add(\"JLD2\")\n",
    "# Pkg.add(\"MLUtils\")\n",
    "# Pkg.add(\"Optimisers\")\n",
    "# Pkg.add(\"Zygote\")\n",
    "# Pkg.add(\"Random\")\n",
    "# Pkg.add(\"Statistics\")\n",
    "# Pkg.add(\"Images\")\n",
    "# Pkg.add(\"FileIO\")\n",
    "# Pkg.add(\"IterTools\")\n",
    "# Pkg.add(\"OneHotArrays\")\n",
    "using Lux, LuxAMDGPU, CUDA, JLD2, MLUtils, Optimisers, Zygote, Random, Statistics, Images, FileIO, IterTools, OneHotArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image processing (assumes data is split into 'good' and 'defective' folders)\n",
    "using Images\n",
    "using Statistics\n",
    "\n",
    "global good_path = \"C:\\\\Users\\\\Vincent Alexander\\\\OneDrive\\\\Desktop\\\\good\" #set as global to be accessed in train function\n",
    "global defective_path = \"C:\\\\Users\\\\Vincent Alexander\\\\OneDrive\\\\Desktop\\\\defective\"\n",
    "\n",
    "function imgProcess(dir_path::AbstractString, output_path::AbstractString, width::Int, height::Int)\n",
    "    for filename in readdir(dir_path)\n",
    "        if endswith(filename, \".jpg\")\n",
    "            img_path = joinpath(dir_path, filename)\n",
    "            img = load(img_path)\n",
    "            #resize image\n",
    "            resizedImage = imresize(img, width, height)\n",
    "            #convert to array to normalize\n",
    "            arr = Array(resizedImage)\n",
    "            mean_val = mean(arr)\n",
    "            std_val = std(arr)\n",
    "            normalized_image = (arr .- mean_val) / std_val\n",
    "            #grayscale the image\n",
    "            processed_image = Gray.(normalized_image)\n",
    "            #save processed image in new path\n",
    "            save(joinpath(output_path, filename), processed_image)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "imgProcess(good_path, \"processed_good_path\", 224, 224)\n",
    "imgProcess(defective_path, \"processed_defective_path\", 224, 224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_data (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Collects tire data and splits into batches for training/testing\n",
    "using Random\n",
    "using OneHotArrays\n",
    "using Images\n",
    "using MLUtils\n",
    "using Statistics\n",
    "\n",
    "function load_data(good_tire_path::String, defective_tire_path::String, batchsize::Int64, train_split::Float64)\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    #put good tires and corresponding labels into x/y data\n",
    "    for (i, file) in enumerate(readdir(good_tire_path))\n",
    "        img = load(joinpath(good_tire_path, file))\n",
    "        push!(x_data, img)\n",
    "        push!(y_data, 0) #Assign 0 label for good tires\n",
    "    end\n",
    "    #put defective tires and corresponding labels into x/y data\n",
    "    for (i, file) in enumerate(readdir(defective_tire_path))\n",
    "        img = load(joinpath(defective_tire_path, file))\n",
    "        push!(x_data, img)\n",
    "        push!(y_data, 1) #Assign 1 label for defective tires\n",
    "    end\n",
    "    #stack images along fourth dimension\n",
    "    x_data = cat(x_data...; dims=4)\n",
    "    #shuffle data\n",
    "    N = length(x_data[1, 1, 1, :])\n",
    "    num_train = Int(floor(N * train_split))\n",
    "    indicies = shuffle(1:N)\n",
    "    \n",
    "    #split data into training and testing sets\n",
    "    x_train = x_data[:, :, :, indicies[1:num_train]]\n",
    "    x_test = x_data[:, :, :, indicies[(num_train + 1):end]]\n",
    "\n",
    "    y_data = onehotbatch(y_data, 0:1)\n",
    "    y_train = y_data[:, indicies[1:num_train]]\n",
    "    y_test = y_data[:, indicies[(num_train+1):end]]\n",
    "    \n",
    "    train_loader = MLUtils.DataLoader((x_train, y_train), batchsize)\n",
    "    test_loader = MLUtils.DataLoader((x_test, y_test), batchsize)\n",
    "    return train_loader, test_loader\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "    layer_1 = Conv((3, 3), 3 => 16, relu),  \u001b[90m# 448 parameters\u001b[39m\n",
       "    layer_2 = MaxPool((2, 2)),\n",
       "    layer_3 = Conv((3, 3), 16 => 32, relu),  \u001b[90m# 4_640 parameters\u001b[39m\n",
       "    layer_4 = MaxPool((2, 2)),\n",
       "    layer_5 = GlobalMeanPool(),\n",
       "    layer_6 = Dense(32 => 128, relu),   \u001b[90m# 4_224 parameters\u001b[39m\n",
       "    layer_7 = Dense(128 => 2, sigmoid_fast),  \u001b[90m# 258 parameters\u001b[39m\n",
       ") \u001b[90m        # Total: \u001b[39m9_570 parameters,\n",
       "\u001b[90m          #        plus \u001b[39m0 states."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#establish the model\n",
    "\n",
    "#define model using chain of layers\n",
    "model = Chain(\n",
    "   Conv((3, 3), 3 => 16, relu),\n",
    "   MaxPool((2, 2)),\n",
    "   Conv((3, 3), 16 => 32, relu),\n",
    "   MaxPool((2, 2)),\n",
    "   GlobalMeanPool(),\n",
    "   Dense(32, 128, relu),  # Adjust the input size (32) and output size (128)\n",
    "   Dense(128, 2, sigmoid),  # 2 classes (good or bad)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define the loss function\n",
    "function xlogy(x, y)\n",
    "    result = x * log(y)\n",
    "    return ifelse(iszero(x), zero(result), result)\n",
    "end\n",
    "\n",
    "function binarycrossentropy(y_pred, y_true)\n",
    "    y_pred = y_pred .+ eps(eltype(y_pred))\n",
    "    return mean(@. -xlogy(y_true, y_pred) - xlogy(1 - y_true, 1 - y_pred))\n",
    "end\n",
    "\n",
    "function compute_loss(x, y, model, ps, st)\n",
    "    y_pred, st = model(x, ps, st)\n",
    "    return binarycrossentropy(y_pred, y), y_pred, st\n",
    "end\n",
    "\n",
    "matches(y_pred, y_true) = sum((y_pred .> 0.5) .== y_true)\n",
    "accuracy(y_pred, y_true) = matches(y_pred, y_true) / length(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_optimiser (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define optimiser\n",
    "function create_optimiser(ps)\n",
    "    opt = Optimisers.ADAM(0.01f0)\n",
    "    return Optimisers.setup(opt, ps)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "batchsize = 100\n",
    "train_split = 0.6\n",
    "train_loader, test_loader = load_data(\"processed_good_path\", \"processed_defective_path\", batchsize, train_split)\n",
    "\n",
    "ps = params(model)\n",
    "\n",
    "optimiser = create_optimiser(ps)\n",
    "init!(optimiser, ps)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "function train(train_loader, test_loader, model, optimiser, ps, epochs)\n",
    "    for epoch in 1:epochs\n",
    "        total_loss = 0.0\n",
    "    \n",
    "        for (x, y) in train_loader\n",
    "            grads, loss = gradient(ps) do\n",
    "                y_pred = model(x, ps)\n",
    "                loss, y_pred = compute_loss(x, y, model, ps, nothing )\n",
    "            end\n",
    "            total_loss += loss\n",
    "            update!(optimizer, ps, grads)\n",
    "        end\n",
    "    \n",
    "        println(\"Epoch: $epoch, Loss: $total_loss\")\n",
    "    end\n",
    "end\n",
    "\n",
    "train(train_loader, test_loader, model, optimiser, ps, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
